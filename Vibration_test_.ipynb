{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpJpLevZ7X1T",
        "outputId": "e335328d-a038-4276-c10a-6ff97d59a289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9339622641509434\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Cracking       0.91      0.96      0.94       159\n",
            "        Ideal       0.95      0.92      0.93       159\n",
            "Offset_Pulley       0.96      0.96      0.96       159\n",
            "         Wear       0.92      0.90      0.91       159\n",
            "\n",
            "     accuracy                           0.93       636\n",
            "    macro avg       0.93      0.93      0.93       636\n",
            " weighted avg       0.93      0.93      0.93       636\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "# 1. Sliding Window Segmentation\n",
        "\n",
        "def segment_signal(data, window_size=1024, step=256):\n",
        "    segments = []\n",
        "    for start in range(0, len(data) - window_size + 1, step):\n",
        "        segments.append(data[start:start+window_size])\n",
        "    return segments\n",
        "\n",
        "\n",
        "# 2. Hjorth Parameters\n",
        "\n",
        "def hjorth_params(data):\n",
        "    diff1 = np.diff(data)\n",
        "    diff2 = np.diff(diff1)\n",
        "    var0 = np.var(data)\n",
        "    var1 = np.var(diff1)\n",
        "    var2 = np.var(diff2)\n",
        "    activity = var0\n",
        "    mobility = np.sqrt(var1 / (var0 + 1e-9))\n",
        "    complexity = np.sqrt(var2 / (var1 + 1e-9)) / (mobility + 1e-9)\n",
        "    return activity, mobility, complexity\n",
        "\n",
        "\n",
        "# 3. Advanced Feature Extraction\n",
        "\n",
        "def extract_features(data):\n",
        "    data = np.array(data)\n",
        "    if len(data) == 0:\n",
        "        return [0]*22\n",
        "\n",
        "    # Time-domain\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    rms = np.sqrt(np.mean(data**2))\n",
        "    peak = np.max(np.abs(data))\n",
        "    skew = pd.Series(data).skew()\n",
        "    kurt = pd.Series(data).kurt()\n",
        "    crest_factor = peak / (rms + 1e-9)\n",
        "    shape_factor = rms / (np.mean(np.abs(data)) + 1e-9)\n",
        "    impulse_factor = peak / (np.mean(np.abs(data)) + 1e-9)\n",
        "    clearance_factor = peak / (np.mean(np.sqrt(np.abs(data))) + 1e-9)\n",
        "    peak_to_peak = np.ptp(data)\n",
        "    variance = np.var(data)\n",
        "    activity, mobility, complexity = hjorth_params(data)\n",
        "\n",
        "    # Frequency-domain\n",
        "    fft_vals = np.abs(rfft(data))\n",
        "    fft_freqs = rfftfreq(len(data), d=1)\n",
        "    dominant_freq = fft_freqs[np.argmax(fft_vals)] if len(fft_vals) > 0 else 0.0\n",
        "\n",
        "    sum_fft_vals = np.sum(fft_vals)\n",
        "    spectral_centroid = np.sum(fft_freqs * fft_vals) / (sum_fft_vals + 1e-9) if sum_fft_vals > 0 else 0.0\n",
        "    spectral_entropy = entropy(fft_vals / (sum_fft_vals + 1e-9)) if sum_fft_vals > 0 else 0.0\n",
        "    spectral_kurtosis = pd.Series(fft_vals).kurt() if len(fft_vals) > 1 else 0.0\n",
        "\n",
        "    band_energy_0_500 = np.sum(fft_vals[(fft_freqs >=0) & (fft_freqs <=500)])\n",
        "    band_energy_500_1000 = np.sum(fft_vals[(fft_freqs >500) & (fft_freqs <=1000)])\n",
        "    band_energy_1000_2000 = np.sum(fft_vals[(fft_freqs >1000) & (fft_freqs <=2000)])\n",
        "\n",
        "    return [\n",
        "        mean, std, rms, peak, skew, kurt,\n",
        "        crest_factor, shape_factor, impulse_factor, clearance_factor,\n",
        "        peak_to_peak, variance, activity, mobility, complexity,\n",
        "        dominant_freq, spectral_centroid, spectral_entropy, spectral_kurtosis,\n",
        "        band_energy_0_500, band_energy_500_1000, band_energy_1000_2000\n",
        "    ]\n",
        "\n",
        "\n",
        "# 4. Load Dataset + Segment + Extract Features\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/IoTeligen/Data\"\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for fault_type in os.listdir(BASE_PATH):\n",
        "    folder = os.path.join(BASE_PATH, fault_type)\n",
        "    if not os.path.isdir(folder):\n",
        "        continue\n",
        "    for sub in os.listdir(folder):\n",
        "        sub_path = os.path.join(folder, sub)\n",
        "        for file in os.listdir(sub_path):\n",
        "            if file.endswith(\".csv\"):\n",
        "                filepath = os.path.join(sub_path, file)\n",
        "                temp_data = []\n",
        "                with open(filepath, 'rb') as f:\n",
        "                    for line in f:\n",
        "                        decoded_line = \"\"\n",
        "                        try:\n",
        "                            decoded_line = line.decode('utf-8')\n",
        "                        except UnicodeDecodeError:\n",
        "                            try:\n",
        "                                decoded_line = line.decode('latin-1')\n",
        "                            except UnicodeDecodeError:\n",
        "                                try:\n",
        "                                    decoded_line = line.decode('cp1252')\n",
        "                                except UnicodeDecodeError:\n",
        "                                    continue\n",
        "\n",
        "                        cleaned_line = decoded_line.strip()\n",
        "\n",
        "                        numerical_part = cleaned_line\n",
        "                        if ',' in cleaned_line:\n",
        "                            parts = cleaned_line.split(',')\n",
        "\n",
        "                            if len(parts) > 1 and parts[1].strip():\n",
        "                                numerical_part = parts[1].strip()\n",
        "                            elif len(parts) > 0 and parts[0].strip():\n",
        "                                numerical_part = parts[0].strip()\n",
        "                            else:\n",
        "                                continue\n",
        "\n",
        "\n",
        "                        numerical_part = numerical_part.replace(',', '.')\n",
        "\n",
        "                        try:\n",
        "                            value = float(numerical_part)\n",
        "                            temp_data.append(value)\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                data = np.array(temp_data)\n",
        "                if len(data) == 0:\n",
        "                    continue\n",
        "\n",
        "                segments = segment_signal(data)\n",
        "                for seg in segments:\n",
        "                    feats = extract_features(seg)\n",
        "                    if not all(x == 0 for x in feats):\n",
        "                        features.append(feats)\n",
        "                        labels.append(fault_type)\n",
        "\n",
        "# 5. DataFrame + Encode + Scale + SMOTE\n",
        "\n",
        "columns = [\n",
        "    \"mean\",\"std\",\"rms\",\"peak\",\"skew\",\"kurt\",\n",
        "    \"crest_factor\",\"shape_factor\",\"impulse_factor\",\"clearance_factor\",\n",
        "    \"peak_to_peak\",\"variance\",\"activity\",\"mobility\",\"complexity\",\n",
        "    \"dominant_freq\",\"spectral_centroid\",\"spectral_entropy\",\"spectral_kurtosis\",\n",
        "    \"band_energy_0_500\",\"band_energy_500_1000\",\"band_energy_1000_2000\"\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(features, columns=columns)\n",
        "df[\"label\"] = labels\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label_encoded\"] = le.fit_transform(df[\"label\"])\n",
        "\n",
        "X = df.drop([\"label\",\"label_encoded\"], axis=1)\n",
        "y = df[\"label_encoded\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "sm = SMOTE()\n",
        "X_res, y_res = sm.fit_resample(X_scaled, y)\n",
        "\n",
        "\n",
        "# 6. Train/Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_res, y_res, test_size=0.25, random_state=42, stratify=y_res\n",
        ")\n",
        "\n",
        "\n",
        "# 7. Tuned XGBoost\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=9,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_lambda=2,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# 8. Evaluation\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))"
      ]
    }
  ]
}